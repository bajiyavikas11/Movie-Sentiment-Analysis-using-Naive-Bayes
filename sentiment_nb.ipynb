{"cells": [{"cell_type": "code", "metadata": {}, "source": ["# Sentiment Analysis using Naive Bayes (IMDb Dataset)", "", "# Step 1: Import Libraries", "import tensorflow_datasets as tfds", "import re", "import nltk", "from nltk.corpus import stopwords", "from sklearn.feature_extraction.text import TfidfVectorizer", "from sklearn.model_selection import train_test_split", "from sklearn.naive_bayes import MultinomialNB", "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix", "import seaborn as sns", "import matplotlib.pyplot as plt", "import numpy as np", "import pickle", "", "# Step 2: Load Dataset", "nltk.download('stopwords')", "data, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)", "train_data, test_data = data['train'], data['test']", "", "X_train, y_train = [], []", "for text, label in tfds.as_numpy(train_data):", "    X_train.append(text.decode(\"utf-8\"))", "    y_train.append(label)", "", "X_test, y_test = [], []", "for text, label in tfds.as_numpy(test_data):", "    X_test.append(text.decode(\"utf-8\"))", "    y_test.append(label)", "", "# Step 3: Clean Text", "def clean_text(text):", "    text = re.sub(r'<.*?>', '', text)", "    text = re.sub(r'[^a-zA-Z\\s]', '', text)", "    text = text.lower()", "    stop_words = set(stopwords.words('english'))", "    text = ' '.join([word for word in text.split() if word not in stop_words])", "    return text", "", "X_train_clean = [clean_text(text) for text in X_train]", "X_test_clean = [clean_text(text) for text in X_test]", "", "# Step 4: Vectorization", "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))", "X_train_vec = vectorizer.fit_transform(X_train_clean)", "X_test_vec = vectorizer.transform(X_test_clean)", "", "# Step 5: Model Training", "model = MultinomialNB()", "model.fit(X_train_vec, y_train)", "", "# Step 6: Evaluation", "y_pred = model.predict(X_test_vec)", "print(\"Accuracy:\", accuracy_score(y_test, y_pred))", "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))", "", "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d',", "            xticklabels=['Neg', 'Pos'], yticklabels=['Neg', 'Pos'])", "plt.xlabel(\"Predicted\")", "plt.ylabel(\"Actual\")", "plt.title(\"Confusion Matrix\")", "plt.show()", "", "# Step 7: Explainability", "feature_names = vectorizer.get_feature_names_out()", "log_probs = model.feature_log_prob_", "", "for i, label in enumerate(['Negative', 'Positive']):", "    top_words = np.argsort(log_probs[i])[-10:]", "    print(f\"\\nTop words for {label}:\")", "    print([feature_names[j] for j in top_words])", "", "# Step 8: Save Model & Vectorizer", "with open('nb_model.pkl', 'wb') as f:", "    pickle.dump(model, f)", "", "with open('tfidf_vectorizer.pkl', 'wb') as f:", "    pickle.dump(vectorizer, f)"], "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 2}